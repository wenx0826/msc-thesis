# A Proposal for a Document-based Process Model Explorer

## 1. Introduction

### 1.1 Motivation

A significant portion of any organization's operational knowledge is not stored in structured databases but is instead embedded within a vast and growing collection of unstructured documents.1 Manuals for standard operating procedures (SOPs), internal policy documents, and project reports all contain detailed descriptions of how work is actually performed. The manual extraction and formal modeling of this "latent" knowledge is the primary bottleneck in the Business Process Management (BPM) lifecycle, proving to be time-consuming, expensive, and susceptible to human error.3

The advent of powerful Large Language Models (LLMs), now accessible through APIs, presents a transformative opportunity to automate the initial translation from text to a formal BPMN model.6 These services can process a natural language description and generate a structured output, drastically reducing the initial modeling effort. However, treating these powerful APIs as infallible "black box" solutions is a critical mistake. The probabilistic nature of LLMs means their output, while often impressive, is susceptible to "hallucinations"—generating plausible but factually incorrect or logically inconsistent information.9 A single misplaced element or an illogical sequence flow can render an entire BPMN model invalid and unusable.10

This creates a new and urgent problem: while the barrier to _generating_ a process model has been lowered, the challenge of _validating and trusting_ this AI-generated output remains. A business analyst or domain expert receiving a model from an API has no direct way to verify its faithfulness to the source text. Without a clear link between the textual description and the resulting diagram, the model is opaque, its origins are untraceable, and correcting subtle errors becomes a frustrating exercise of guesswork. The API accelerates the first draft, but it does not solve the fundamental need for human oversight, contextual correction, and validation to ensure the final model accurately reflects reality.

This project, the "Document-based Process Model Explorer," is motivated by this critical gap between automated generation and human validation. The core innovation is not in building another generative model, but in designing and evaluating a **human-in-the-loop system** that makes the output of an external, black-box AI service transparent, verifiable, and refinable. As envisioned in the mockup, the Explorer will create an **interactive visual analytics environment** that allows a user to visually trace the connections between source text fragments and the corresponding model elements generated by the API.11 This interactive paradigm directly confronts the limitations of opaque, one-shot generation by empowering the user to become an active participant in the sensemaking and validation process, ensuring the final model is both formally correct and semantically faithful to the original knowledge.

### 1.2 Research Questions

This thesis is guided by the following research questions, which focus on the integration and evaluation of a generative API within a novel interactive system.

- RQ1: How accurately can a state-of-the-art, third-party generative AI API generate syntactically and semantically correct BPMN 2.0 models from unstructured procedural texts?
    
    This question establishes a performance baseline for the "black box" component of the system. It moves beyond a simple "yes/no" to investigate the quality of the raw, automated output. To answer this, a quantitative evaluation will be performed. A "gold standard" dataset of text-model pairs will be created. The API's generated models will be systematically compared against this standard using metrics like precision, recall, F1-score for model elements, and graph-edit distance for structural similarity.13 This provides an objective measure of the API's out-of-the-box capabilities and quantifies the "problem" that the interactive system aims to solve.
    
- RQ2: How can an interactive visual interface, featuring bidirectional linking between source text and model elements, improve a user's ability to effectively validate and correct the output of an automated process model generation API?
    
    This question focuses on the core contribution of the thesis: the interactive system itself. It seeks to measure the value added by the "glass box" interface in overcoming the opaqueness of the API. The answer will be derived from a formal user study. A key metric will be the measurable improvement in model quality (re-evaluated against the gold standard) after a user has performed corrections using the system, compared to the baseline quality from RQ1. This will be supplemented by task completion rates and qualitative feedback.15
    
- RQ3: What specific interactive features and visual cues are most effective in facilitating the cognitive process of aligning textual descriptions with their corresponding API-generated BPMN model elements?
    
    This question delves deeper into the HCI aspect, aiming to identify which design choices contribute most to the system's effectiveness. While RQ2 asks if the interface helps, RQ3 asks how it helps. This will be investigated through the qualitative analysis of the user study data. By analyzing user behaviors, comments from the think-aloud protocol, and interview responses, we can identify which features (e.g., bidirectional highlighting, the properties panel, the regeneration feedback loop) were most crucial for users to identify and fix errors in the API's output.
    

### 1.3 Contribution

This research will make three primary contributions to the fields of Business Process Management (BPM) and Human-Computer Interaction (HCI), focusing on the effective application of generative AI.

1. **A Novel System Architecture for Human-AI Collaboration:** The project will deliver the design and implementation of an integrated system that effectively "wraps" a powerful but imperfect generative AI service with a user-centric interactive front-end. The contribution is the blueprint for a complete, end-to-end workflow that transforms an opaque API call into a transparent and trustworthy modeling process.
    
2. **An Interactive Validation and Refinement Paradigm:** The core innovation is the development and application of a bidirectional synchronization mechanism that visually links textual phrases to the BPMN elements generated by an external API. This feature provides a novel method for model validation and traceability, creating a "glass box" that allows users to understand the basis for the AI's output. This moves beyond the state-of-the-art by directly addressing the critical problem of trust and verifiability in AI-generated artifacts.
    
3. **A Rigorous Empirical Evaluation of a Human-in-the-Loop System:** The thesis will provide a comprehensive evaluation that first benchmarks the performance of a black-box generative API for process modeling (RQ1), and then empirically demonstrates the value added by the interactive system in improving the quality of those models (RQ2 & RQ3). This dual evaluation provides a holistic validation of the proposed human-in-the-loop solution.
    

### 1.4 Methodology

This project will be conducted using the **Design Science Research Methodology (DSRM)**, a well-established framework for research in Information Systems.17 DSR is perfectly suited for this project as its primary goal is the creation and evaluation of a novel IT artifact designed to solve a relevant, real-world problem—in this case, the problem of validating and refining models generated by opaque AI services.19

**(1) Summary of Design Science Research**

Design Science Research is a problem-solving paradigm focused on creating innovative artifacts to address specific challenges.21 Unlike behavioral science, which seeks to

_explain_ reality, design science aims to _create_ useful things.19 The process is inherently iterative, cycling through the activities of building an artifact and evaluating its performance in a given context.20 Hevner et al. describe this through three interconnected cycles: the

_Relevance Cycle_ (connecting to the problem environment), the _Rigor Cycle_ (grounding in existing knowledge), and the _Design Cycle_ (the core build-and-evaluate loop).21 The outputs of DSR are the artifact itself and the knowledge gained in the process.23

**(2) Application of DSRM to this Project**

- **Stakeholders:** The primary stakeholders are individuals involved in managing business processes who stand to benefit from more efficient and accessible modeling tools.24 This includes:
    
    - **Business Analysts and Process Modelers:** Who will use the tool to accelerate their work by quickly validating and correcting API-generated drafts.
        
    - **Domain Experts / Subject Matter Experts (SMEs):** Who can use the intuitive interface to validate models without needing deep BPMN expertise.
        
    - **Managers:** Who rely on accurate process models for decision-making.
        
- **Artifacts:** The research will produce several artifacts consistent with the DSR framework:20
    
    - **Models:** The high-level system architecture that integrates an external generative API with an interactive frontend via a backend orchestration layer.
        
    - **Methods:** The prompt engineering strategies used to instruct the external API to return not only the process model but also the necessary source mapping data.
        
    - **Instantiation:** The final, implemented "Document-based Process Model Explorer" web application. This application is the primary artifact and the object of evaluation.
        
- **Steps:** The research will follow the six-step DSRM process model:17
    
    1. **Problem Identification and Motivation:** This is detailed in Section 1.1. The problem is the lack of trust, transparency, and verifiability in process models generated by black-box AI APIs.
        
    2. **Define Objectives for a Solution:** The objectives are to create a system that (a) seamlessly integrates with a third-party generation API, (b) makes the API's output transparent through interactive visualization, and (c) enables users to efficiently validate and correct the generated model.
        
    3. **Design and Development:** This phase involves designing the system architecture and implementing the backend API orchestration layer and the frontend visualization interface. The focus is on the _system_, not the internal AI model.
        
    4. **Demonstration:** The artifact will be used to solve the problem, showcasing the workflow of uploading a document, receiving an API-generated model, and using the interactive features to validate and refine it.
        
    5. **Evaluation:** This crucial step involves rigorously evaluating the artifact against the objectives, as detailed in the Evaluation section (1.5).
        
    6. **Communication:** The results will be communicated through the master's thesis document.
        

### 1.5 Evaluation

A robust, two-part evaluation strategy will be employed to rigorously assess the developed artifact and answer the research questions. A ground-truth dataset will be established, consisting of 10-15 procedural text documents and their corresponding "gold standard" BPMN models, manually created by an expert.

**Part 1: Baseline Performance Analysis of the Generative API (for RQ1)**

This evaluation will objectively measure the quality of the raw output from the external, black-box API. For each document in the test dataset, a BPMN model will be generated via an API call. This model will then be systematically compared against the gold standard using established metrics.

- **Element-level Analysis:** The set of generated elements (tasks, gateways) will be compared to the gold standard to calculate **Precision, Recall, and F1-score**.
    
- **Structural Analysis:** The graph structure of the generated model will be compared to the gold standard using a **graph-edit distance** algorithm to produce a quantitative score of their structural similarity.13
    

**Part 2: Evaluation of the Interactive Explorer's Effectiveness (for RQ2 & RQ3)**

This evaluation will assess the value added by the interactive system from a human user's perspective. A formal user study will be conducted with 10-15 participants.

- **Task-based Scenarios:** Participants will be given the raw, API-generated models and the source texts. Their task will be to use the "Document-based Process Model Explorer" to find and correct any discrepancies.
    
- **Effectiveness Measurement:** The primary metric will be the **improvement in model quality**. The corrected models produced by the users will be compared against the gold standard using the same F1-score and graph-edit distance metrics from Part 1. A significant improvement over the baseline API score will demonstrate the effectiveness of the system.
    
- **Usability Measurement:** After completing the tasks, each participant will complete the **System Usability Scale (SUS)** questionnaire, a reliable industry standard that yields a score from 0 to 100 representing perceived usability.15
    
- **Qualitative Feedback:** A think-aloud protocol and post-session interviews will be used to gather in-depth feedback on which interactive features were most helpful for identifying and fixing errors, directly addressing RQ3.
    

### 1.6 Structure

The final thesis will be organized into the following chapters:

- **Chapter 1: Introduction:** Presents the motivation, research questions, contributions, and methodology.
    
- **Chapter 2: Related Work:** Reviews the state of the art in BPMN, text-based process discovery (contextualizing the API's function), and interactive visual analytics for human-AI collaboration.
    
- **Chapter 3: System Design and Architecture:** Details the design of the "Document-based Process Model Explorer," focusing on the backend API orchestration layer and the frontend interactive interface.
    
- **Chapter 4: Implementation:** Describes the implementation of the system, including the technologies and libraries used (e.g., `bpmn-js`), and the prompt engineering strategies developed for the API.
    
- **Chapter 5: Evaluation:** Presents the methodology and results of the two-part evaluation: the baseline API performance analysis and the user study of the interactive system.
    
- **Chapter 6: Discussion:** Interprets the evaluation results, discusses their implications for the research questions, and acknowledges limitations.
    
- **Chapter 7: Conclusion and Future Work:** Summarizes the contributions and proposes directions for future research.
    

## 2. Related Work

_(This section is adapted from the "Background and State of the Art" section of the initial report.)_

### 2.1 Foundations of Business Process Modeling with BPMN 2.0

Business Process Model and Notation (BPMN) is the de facto international standard for graphically representing business processes.6 Its value lies in providing a standardized visual language that is intuitive for business stakeholders while being precise enough for technical implementation.10 This allows BPMN to serve as a critical bridge, closing the communication gap between business design and IT implementation.10 The core elements include Flow Objects (Events, Activities, Gateways) and Connecting Objects (Sequence Flows) that form the target structure for any text-to-model generation task.10

### 2.2 The Evolution of Process Discovery: From Event Logs to Text Mining

The field of process discovery has traditionally been dominated by Process Mining, which analyzes structured event logs from enterprise systems.1 However, a key limitation is its dependence on these logs, as much process knowledge exists only in unstructured documents.1 This has spurred the growth of Automated Business Process Discovery (ABPD) from text, which applies NLP to discover "hidden" processes.4 This thesis is situated in this area, focusing specifically on the challenges and opportunities presented by the availability of powerful, general-purpose LLM APIs for this task.8

### 2.3 A Survey of NLP Techniques for Process Element Extraction

The technical challenge of transforming natural language into a structured BPMN model has seen significant evolution. Early systems used brittle rule-based methods, followed by supervised machine learning techniques like Named Entity Recognition (NER) that required expensive, manually annotated datasets.30 The recent emergence of Large Language Models (LLMs), accessible via APIs, has catalyzed a paradigm shift, enabling end-to-end Text-to-BPMN conversion with minimal task-specific training.6 However, the probabilistic nature of these models makes them prone to "hallucinations" and the generation of syntactically invalid output.10 To mitigate this, a

**hybrid approach** has emerged, where an LLM is used for semantic understanding to produce a structured intermediate format (e.g., JSON), and a deterministic algorithm constructs the final, valid BPMN model.9 This project assumes the external API performs a similar function, but acknowledges the inherent risks of this approach, which motivates the need for an interactive validation layer.

### 2.4 Paradigms for Interactive Process Model Analysis and Refinement

The automated generation of a process model is only the first step. The model must be explored, validated, and refined by domain experts.33 The proposed system's interactive features are grounded in established principles from

**Visual Analytics (VA)** and **Interactive Machine Learning**. VA is the science of analytical reasoning facilitated by interactive visual interfaces, emphasizing the synergy between automated analysis and human cognition.8 The core VA principle of "Analyze First, Show the Important, Zoom, Filter and Analyze Further, Details on Demand" provides a theoretical foundation for the Explorer's design.8 Similarly, Interactive Machine Learning explores systems where users provide feedback to iteratively guide and refine a model's behavior.36 The "Regenerate" function envisioned in the mockup is a direct application of this paradigm, creating a feedback loop that transforms the user from a passive consumer of an API's output into an active co-creator of a validated, trustworthy model.