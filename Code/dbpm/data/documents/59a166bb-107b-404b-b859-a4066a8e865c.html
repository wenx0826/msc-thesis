
```
API is known and developed, provided by my advisor. I don't want to conduct any analysis on it at the moment.
```

# A Proposal for a Document-based Process Model Explorer

## 1. Introduction

### 1.1 Motivation

A significant portion of any organization's operational knowledge is embedded within unstructured documents like manuals, reports, and standard operating procedures. Manually extracting this knowledge into formal process models is a primary bottleneck in the Business Process Management (BPM) lifecycle—a process that is slow, expensive, and prone to human error.  

The availability of advanced AI APIs, capable of transforming natural language text into a structured process model, presents a powerful solution to this initial challenge. For this project, such an API, which generates models in the CPEE notation, is provided as a foundational component. This technology can produce a draft model in seconds, a task that might take a human analyst hours or days.

However, this automation introduces a new critical problem: the "black box" dilemma. The API delivers a complete process model, but ==the user has no insight into _how_ the textual description was interpreted to create the final diagram. This lack of transparency creates a significant trust gap. Is the model a faithful representation of the source text? Are there subtle misinterpretations or logical errors hidden within the diagram? Without a clear and intuitive way to trace the connections between the source document and the generated model, the tasks of validation and correction remain difficult and time-consuming.== The API provides a starting point, but the fundamental need for human oversight, contextual refinement, and validation remains unsolved.

This project, the "Document-based Process Model Explorer," is motivated by this critical gap between opaque automated generation and the need for human-centric validation. The core innovation of this thesis is not the generative AI itself, but the design and evaluation of a **human-in-the-loop system** that makes the output of the provided API transparent, verifiable, and refinable. As envisioned in the mockup, the Explorer will create an **interactive visual analytics environment**. This system will empower a user to visually trace the connections between source text fragments and their corresponding model elements, enabling them to confidently validate the API's output and efficiently make necessary corrections. This research directly addresses the challenge of building trustworthy and effective systems around powerful, but imperfect, generative AI services.  

### 1.2 Research Questions

This thesis is guided by the following research questions, which focus on the design, effectiveness, and usability of the interactive system built around the provided API.

- **RQ1: How can an interactive visual analytics system be designed to effectively bridge the semantic gap between an unstructured textual document and the structured CPEE process model generated by a black-box AI service?** This question focuses on the core design of the artifact. The answer will be the system architecture and the set of features proposed and implemented in this thesis. It addresses the challenge of creating an interface that makes the relationship between two very different representations of information (unstructured text and a formal graph model) intuitive and understandable to a user.
    
- **RQ2: To what extent does the use of an interactive visual interface, featuring bidirectional linking, improve a user's ability to validate and correct errors in an API-generated CPEE model?** This question addresses the practical effectiveness of the system. It seeks to measure the tangible value added by the interactive features. This will be answered through a formal user study where the quality of a model, after being corrected by a user with the tool, is quantitatively measured against a "gold standard." The goal is to demonstrate that the system enables users to significantly improve upon the raw output of the API.
    
- **RQ3: What specific interactive features and visual cues are most effective in facilitating the cognitive process of aligning textual descriptions with their corresponding API-generated CPEE model elements?** This question delves deeper into the usability and HCI aspects of the system. It aims to identify which design choices contribute most to the system's success. This will be investigated through qualitative analysis of user study data, including think-aloud protocols and interviews, to understand which features users found most helpful for identifying and fixing errors.
    

### 1.3 Contribution

This research will make three primary contributions to the fields of Business Process Management (BPM) and Human-Computer Interaction (HCI), focusing on the effective application of generative AI.

1. **A Novel System Architecture for Human-AI Collaboration:** The project will deliver the design and implementation of an integrated system that effectively "wraps" a powerful but opaque generative AI service with a user-centric interactive front-end. The contribution is the blueprint for a complete, end-to-end workflow that transforms an API call into a transparent and trustworthy modeling process.
    
2. **An Interactive Validation and Refinement Paradigm:** The core innovation is the development and application of a bidirectional synchronization mechanism that visually links textual phrases to the CPEE model elements generated by an external API. This feature provides a novel method for model validation and traceability, creating a "glass box" that allows users to understand the basis for the AI's output, directly addressing the critical problem of trust in AI-generated artifacts.
    
3. **A Rigorous Empirical Evaluation of a Human-in-the-Loop System:** The thesis will provide a comprehensive evaluation focused entirely on the interactive system. Through a formal user study, it will empirically demonstrate the value added by the system in helping users improve the quality of API-generated models (addressing RQ2 and RQ3), providing a validated solution for human-AI co-creation in the process modeling domain.
    

### 1.4 Methodology

This project will be conducted using the **Design Science Research Methodology (DSRM)**, a well-established framework for research in Information Systems. DSR is perfectly suited for this project as its primary goal is the creation and evaluation of a novel IT artifact designed to solve a relevant, real-world problem—in this case, the problem of validating and refining models generated by opaque AI services.  

**(1) Summary of Design Science Research**

Design Science Research is a problem-solving paradigm focused on creating innovative artifacts to address specific challenges. Unlike behavioral science, which seeks to  

_explain_ reality, design science aims to _create_ useful things. The process is inherently iterative, cycling through the activities of building an artifact and evaluating its performance in a given context. Hevner et al. describe this through three interconnected cycles: the  

_Relevance Cycle_ (connecting to the problem environment), the _Rigor Cycle_ (grounding in existing knowledge), and the _Design Cycle_ (the core build-and-evaluate loop). The outputs of DSR are the artifact itself and the knowledge gained in the process.  

**(2) Application of DSRM to this Project**

- **Stakeholders:** The primary stakeholders are individuals involved in managing business processes who stand to benefit from more efficient and accessible modeling tools. This includes:  
    
    - **Business Analysts and Process Modelers:** Who will use the tool to accelerate their work by quickly validating and correcting API-generated drafts.
        
    - **Domain Experts / Subject Matter Experts (SMEs):** Who can use the intuitive interface to validate models without needing deep expertise in formal modeling.
        
    - **Managers:** Who rely on accurate process models for decision-making.
        
- **Artifacts:** The research will produce several artifacts consistent with the DSR framework:  
    
    - **Models:** The high-level system architecture that integrates an external generative API with an interactive frontend via a backend orchestration layer.
        
    - **Methods:** The specific workflow for using the interactive system to validate and refine an API-generated process model.
        
    - **Instantiation:** The final, implemented "Document-based Process Model Explorer" web application. This application is the primary artifact and the object of evaluation.
        
- **Steps:** The research will follow the six-step DSRM process model:  
    
    1. **Problem Identification and Motivation:** This is detailed in Section 1.1. The problem is the lack of trust, transparency, and verifiability in process models generated by black-box AI APIs.
        
    2. **Define Objectives for a Solution:** The objectives are to create a system that (a) seamlessly integrates with the provided API, (b) makes the API's output transparent through interactive visualization, and (c) enables users to efficiently validate and correct the generated model.
        
    3. **Design and Development:** This phase involves designing the system architecture and implementing the backend API orchestration layer and the frontend visualization interface. The focus is on the _system_, not the internal AI model.
        
    4. **Demonstration:** The artifact will be used to solve the problem, showcasing the workflow of uploading a document, receiving an API-generated model, and using the interactive features to validate and refine it.
        
    5. **Evaluation:** This crucial step involves rigorously evaluating the artifact against the objectives, as detailed in the Evaluation section (1.5).
        
    6. **Communication:** The results will be communicated through the master's thesis document.
        

### 1.5 Evaluation

The evaluation will focus entirely on the effectiveness, usability, and utility of the "Document-based Process Model Explorer" artifact. A comprehensive user study will be conducted to assess the system's value in a realistic context and to answer the research questions. A ground-truth dataset will be established, consisting of 10-15 procedural text documents and their corresponding "gold standard" CPEE models, manually created by an expert.

**User Study Design**

The study will be conducted with 10-15 participants, ideally individuals with some familiarity with business processes but not necessarily deep expertise in formal modeling (e.g., business students or junior analysts).

- **Task-based Scenarios:** Participants will be given a document and the corresponding raw CPEE model generated by the provided API. Their task will be to use the "Document-based Process Model Explorer" to review the model, identify any discrepancies between it and the source text, and use the system's features to make corrections.
    
- **Effectiveness Measurement (for RQ2):** The primary quantitative metric will be the **improvement in model quality**. The corrected models produced by the users will be compared against the gold standard using metrics such as F1-score (for elements) and graph-edit distance (for structure). A statistically significant improvement between the raw API model's score and the user-corrected model's score will demonstrate the system's effectiveness.  
    
- **Usability Measurement (for RQ2 & RQ3):** After completing the tasks, each participant will complete the **System Usability Scale (SUS)** questionnaire. This is a reliable, industry-standard 10-item survey that yields a single score from 0 to 100, representing the overall perceived usability of the system.  
    
- **Qualitative Feedback (for RQ3):** A think-aloud protocol will be used during the study, where participants verbalize their thought processes. This will be followed by a semi-structured interview to gather in-depth feedback on their experience, focusing specifically on which interactive features (e.g., the bidirectional linking, properties panel) were most helpful for identifying and fixing errors.
    

### 1.6 Structure

The final thesis will be organized into the following chapters:

- **Chapter 1: Introduction:** Presents the motivation, research questions, contributions, and methodology.
    
- **Chapter 2: Related Work:** Reviews the state of the art in process modeling with the CPEE notation, text-based process discovery (contextualizing the API's function), and interactive visual analytics for human-AI collaboration.
    
- **Chapter 3: System Design and Architecture:** Details the design of the "Document-based Process Model Explorer," focusing on the backend API orchestration layer and the frontend interactive interface.
    
- **Chapter 4: Implementation:** Describes the implementation of the system, including the technologies, libraries, and the strategies for interfacing with the provided API.
    
- **Chapter 5: Evaluation:** Presents the methodology and results of the user study, detailing the findings from the model quality improvement analysis, the SUS scores, and the qualitative feedback.
    
- **Chapter 6: Discussion:** Interprets the evaluation results, discusses their implications for the research questions, and acknowledges limitations.
    
- **Chapter 7: Conclusion and Future Work:** Summarizes the contributions and proposes directions for future research.
    

## 2. Related Work

### 2.1 Foundations of the CPEE Process Model Notation

The Cloud Process Execution Engine (CPEE) is a modular, service-oriented workflow engine designed as a lightweight and scalable alternative to traditional BPM Systems. For user-facing modeling, the engine employs a graphical notation that is visually similar to established standards, using familiar elements such as tasks, events, and gateways connected by sequence flows. However, the underlying semantics are tailored for the CPEE's flexible and distributed architecture, prioritizing direct executability. A foundational understanding of these core visual elements is essential, as they form the target structure that the provided API generates from text.  

### 2.2 The Evolution of Process Discovery: From Event Logs to Text Mining

The field of process discovery has traditionally been dominated by Process Mining from structured event logs. However, much process knowledge exists only in unstructured documents. This has spurred the growth of Automated Business Process Discovery (ABPD) from text, which applies NLP to discover these "hidden" processes. This thesis is situated in this area, focusing specifically on the challenges of validating and refining the output of text-to-model APIs.  

### 2.3 A Survey of NLP Techniques for Process Element Extraction

The technical challenge of transforming natural language into a structured process model has seen significant evolution. Early systems used brittle rule-based methods, followed by supervised machine learning techniques that required expensive, manually annotated datasets. The recent emergence of Large Language Models (LLMs), accessible via APIs, has catalyzed a paradigm shift, enabling end-to-end text-to-model conversion. However, the probabilistic nature of these models makes them prone to "hallucinations" and the generation of syntactically invalid output. This project accepts the output of such an API as a given and focuses on the subsequent human-in-the-loop validation, which is necessary to mitigate the inherent risks of this automated approach.  

### 2.4 Paradigms for Interactive Process Model Analysis and Refinement

The automated generation of a process model is only the first step. The model must be explored, validated, and refined by domain experts. The proposed system's interactive features are grounded in established principles from  

**Visual Analytics (VA)** and **Interactive Machine Learning**. VA is the science of analytical reasoning facilitated by interactive visual interfaces, emphasizing the synergy between automated analysis and human cognition. The core VA principle of "Analyze First, Show the Important, Zoom, Filter and Analyze Further, Details on Demand" provides a theoretical foundation for the Explorer's design. Similarly, Interactive Machine Learning explores systems where users provide feedback to iteratively guide and refine a model's behavior. The "Regenerate" function envisioned in the mockup is a direct application of this paradigm, creating a feedback loop that transforms the user from a passive consumer of an API's output into an active co-creator of a validated, trustworthy model.  

Google 账号

Xin Wen

wx862149260@gmail.com